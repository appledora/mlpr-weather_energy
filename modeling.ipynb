{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sns.set_style(\"whitegrid\")\n",
    "import os\n",
    "from skimpy import skim\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"data/train.csv\")\n",
    "test = pd.read_csv(r\"data/test.csv\")\n",
    "# skim(train)\n",
    "numerical_features=train.select_dtypes('number').columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, test_df):\n",
    "    missing_columns_train = [col for col in df.columns if df[col].isnull().any()]\n",
    "    print(\"Columns with Missing values in train set:\", missing_columns_train)\n",
    "    missing_columns_test = [col for col in test_df.columns if test_df[col].isnull().any()]\n",
    "    print(\"Columns with Missing values in test set:\", missing_columns_test)\n",
    "\n",
    "    df.loc[df[\"year_built\"] == 0, \"year_built\"] = np.nan\n",
    "    test_df.loc[test_df[\"year_built\"] == 0, \"year_built\"] = np.nan\n",
    "\n",
    "    imputer = SimpleImputer()\n",
    "    imputer.fit(train[missing_columns_train])\n",
    "    data_transformed = imputer.transform(train[missing_columns_train])\n",
    "    df[missing_columns_train] = pd.DataFrame(data_transformed)\n",
    "    test_data_transformed = imputer.transform(test[missing_columns_test])\n",
    "    test_df[missing_columns_test] = pd.DataFrame(test_data_transformed)\n",
    "\n",
    "    print(\"Columns with Missing values in train set after imputation:\", df.columns[df.isnull().any()])\n",
    "    print(\"Columns with Missing values in test set after imputation:\", test_df.columns[test_df.isnull().any()])\n",
    "\n",
    "    return df, test_df\n",
    "\n",
    "\n",
    "def categorical_label_encoding(df, test_df):\n",
    "    object_cols = []\n",
    "    int_cols = []\n",
    "    float_cols = []\n",
    "    for col in df.columns:\n",
    "        if col != \"site_eui\":\n",
    "            if df[col].dtype == \"object\":\n",
    "                object_cols.append(col)\n",
    "            elif df[col].dtype == \"int64\":\n",
    "                int_cols.append(col)\n",
    "            elif df[col].dtype == \"float64\":\n",
    "                float_cols.append(col)\n",
    "    print(f\"Starting Label Encoding for {object_cols}\")\n",
    "    le = LabelEncoder()\n",
    "    for col in object_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        test_df[col] = le.fit_transform(test_df[col])\n",
    "\n",
    "    return df, test_df\n",
    "\n",
    "\n",
    "def scale_data(df, test_df):\n",
    "    print(\"Scaling Data with StandardScaler\")\n",
    "    import copy\n",
    "\n",
    "    # code copied from https://www.kaggle.com/usharengaraju/wids2022-lgbm-starter-w-b\n",
    "    y_df = df[\"site_eui\"]\n",
    "    df = df.drop([\"site_eui\", \"id\"], axis=1)\n",
    "    test_df = test_df.drop([\"id\"], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    # return scaled data as a pandas dataframe including their original column names\n",
    "    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    test_df = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)\n",
    "    return df, test_df, y_df\n",
    "\n",
    "\n",
    "def feature_selection(df, test_df):\n",
    "    print(\"Feature Selection\")\n",
    "    # drop features where standard deviation is 0\n",
    "    drop_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].std() == 0 or df[col].std() == np.nan:\n",
    "            if col != \"site_eui\":\n",
    "                drop_cols.append(col)\n",
    "                print(col)\n",
    "\n",
    "    for col in test_df.columns:\n",
    "        if test_df[col].std() == 0 or test_df[col].std() == np.nan:\n",
    "            if col != \"site_eui\":\n",
    "                drop_cols.append(col)\n",
    "                print(col)\n",
    "    return drop_cols\n",
    "\n",
    "\n",
    "def preprocess_data(df, test_df):\n",
    "    df, test_df = fill_missing_values(df, test_df)\n",
    "    df, test_df = categorical_label_encoding(df, test_df)\n",
    "    df, test_df, y_df = scale_data(df, test_df)\n",
    "    print(\"Preprocessing Done\")\n",
    "    print(\"Train Data Shape:\", df.shape)\n",
    "    print(\"Test Data Shape:\", test_df.shape)\n",
    "    return df, test_df, y_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with Missing values in train set: ['year_built', 'energy_star_rating', 'direction_max_wind_speed', 'direction_peak_wind_speed', 'max_wind_speed', 'days_with_fog']\n",
      "Columns with Missing values in test set: ['year_built', 'energy_star_rating', 'direction_max_wind_speed', 'direction_peak_wind_speed', 'max_wind_speed', 'days_with_fog']\n"
     ]
    }
   ],
   "source": [
    "df, test_df = preprocess_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train set into train and test for model validation  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    preprocessed_df, y_df, test_size=0.25, random_state=42)\n",
    "print(\"Train Data Shape:\", X_train.shape)\n",
    "print(\"Test Data Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling \n",
    "We model the data as a regression problem. We use the following models:\n",
    "- Linear Regression\n",
    "- Decision Tree Regressor\n",
    "- Random Forest Regressor\n",
    "- Gradient Boosting (GBM)\n",
    "- Light Gradient Boosting (Light GBM)\n",
    "- Extreme Gradient Boosting (XGBM)\n",
    "Prior to choosing the best performing model, we first compare the R2 scores of each model in their default settings. For the models that perform well, we then tune their hyperparameters to improve their performance. Cross-validation is used to improve the generalization of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class which return cross-val mean R2 score \n",
    "\n",
    "class CV_regression_model ():\n",
    "    def __init__(self, model_name, model, X, y, folds=5):\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.folds = folds\n",
    "        self.results = None \n",
    "        self.mean_score = None\n",
    "        self.std_score = None\n",
    "\n",
    "    def fit(self):\n",
    "        scores = cross_val_score(self.model, self.X, self.y, cv=self.folds, scoring='r2')\n",
    "        self.results = scores\n",
    "        self.mean_score = np.mean(scores)\n",
    "        self.std_score = np.std(scores)\n",
    "\n",
    "    def print_results(self):\n",
    "        print(f\"Model: {self.model_name}\")\n",
    "        print(f\"Mean R2 score: {self.mean_score}\")\n",
    "        print(f\"Standard Deviation: {self.std_score}\")\n",
    "        print(f\"R2 scores: {self.results}\")\n",
    "\n",
    "    def r2_scores(self):\n",
    "        return round(self.mean_score, 4), round(self.std_score, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression() \n",
    "lr = CV_regression_model(\"Linear Regression\", lr_model, X_train, y_train)\n",
    "lr.fit()\n",
    "lr.print_results()\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt = CV_regression_model(\"Decision Tree\", dt_model, X_train, y_train)\n",
    "dt.fit()\n",
    "dt.print_results()\n",
    "df_r2_score.append(dt.r2_scores())\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr_model = RandomForestRegressor(random_state=42)\n",
    "rfr = CV_regression_model(\"Random Forest\", rfr_model, X_train, y_train)\n",
    "rfr.fit()\n",
    "rfr.print_results()\n",
    "df_r2_score.append(rfr.r2_scores())\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr_model = GradientBoostingRegressor(random_state=42)\n",
    "gbr = CV_regression_model(\"Gradient Boosting\", gbr_model, X_train, y_train)\n",
    "gbr.fit()\n",
    "gbr.print_results()\n",
    "df_r2_score.append(gbr.r2_scores())\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "xgbr_model =  XGBRegressor(random_state=42)\n",
    "xgbr = CV_regression_model(\"XGBoost\", xgbr_model, X_train, y_train)\n",
    "xgbr.fit()\n",
    "xgbr.print_results()\n",
    "df_r2_score.append(xgbr.r2_scores())\n",
    "import lightgbm\n",
    "lgbm_model = lightgbm.LGBMRegressor(random_state=42)\n",
    "lgbm = CV_regression_model(\"LightGBM\", lgbm_model, X_train, y_train)\n",
    "lgbm.fit()\n",
    "lgbm.print_results()\n",
    "df_r2_score.append(lgbm.r2_scores())\n",
    "\n",
    "# Define a data frame that includes R2 score and model numbers. \n",
    "result = pd.DataFrame()\n",
    "df_model = [\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\", \"XGBoost\", \"LightGBM\"]\n",
    "# Assigne model name and R2 scores \n",
    "result['model'] = df_model\n",
    "result['r2'] = df_r2 \n",
    "\n",
    "# make barplot of result\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='model', y='r2', data=result)\n",
    "plt.title('R2 Scores of Models')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('eda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be96da3537549bd5b23c4265fca5120bd1897fe4051b8d108ed9070dd5e9d388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
